{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-26T14:51:53.995130Z",
     "start_time": "2025-04-26T14:51:53.037881Z"
    }
   },
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "IMAGE_PATH = kagglehub.dataset_download(\"arnaud58/landscape-pictures\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/gabrielmindlberger/.cache/kagglehub/datasets/arnaud58/landscape-pictures/versions/2\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:02:46.390006Z",
     "start_time": "2025-04-26T15:02:46.386130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 2. Device config\n",
    "device = torch.device(\n",
    "    'mps' if torch.backends.mps.is_available()\n",
    "    else 'cuda' if torch.cuda.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "print(f'Using device: {device}')"
   ],
   "id": "bf0603e3e9f52de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:00:20.802791Z",
     "start_time": "2025-04-26T15:00:20.796502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Hyperparameters\n",
    "img_height, img_width = 256, 256\n",
    "batch_size            = 16\n",
    "num_epochs            = 1\n",
    "learning_rate         = 1e-3"
   ],
   "id": "8a5677ab3e22e953",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:03:05.913576Z",
     "start_time": "2025-04-26T15:03:05.891170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Dataset: load color image, generate grayscale on‐the‐fly\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform_gray=None, transform_color=None):\n",
    "        self.paths = sorted([\n",
    "            os.path.join(img_dir, f)\n",
    "            for f in os.listdir(img_dir)\n",
    "            if f.lower().endswith(('.jpg','.png'))\n",
    "        ])\n",
    "        self.transform_gray  = transform_gray\n",
    "        self.transform_color = transform_color\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        # color target\n",
    "        target = img.copy()\n",
    "        if self.transform_color:\n",
    "            target = self.transform_color(target)\n",
    "        # grayscale input\n",
    "        gray = img.convert('L')\n",
    "        if self.transform_gray:\n",
    "            gray = self.transform_gray(gray)\n",
    "        return gray, target\n",
    "\n",
    "# 5. Transforms (resize + ToTensor)\n",
    "transform_gray = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_color = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 6. DataLoader\n",
    "dataset   = ColorizationDataset(IMAGE_PATH, transform_gray, transform_color)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "print(f'Loaded {len(dataset)} images.')"
   ],
   "id": "4c6e4d00cd0f6004",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4319 images.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:03:07.582850Z",
     "start_time": "2025-04-26T15:03:07.557316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7. Model\n",
    "class ImageColorizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.enc2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.enc3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        # Decoder\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.dec1 = nn.Conv2d(256, 128, 3, padding=1)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.dec2 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.final = nn.Conv2d(64, 3, 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.enc1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.enc2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.enc3(x))\n",
    "        x = self.up1(x)\n",
    "        x = self.relu(self.dec1(x))\n",
    "        x = self.up2(x)\n",
    "        x = self.relu(self.dec2(x))\n",
    "        x = self.sigmoid(self.final(x))\n",
    "        return x\n",
    "\n",
    "model     = ImageColorizer().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ],
   "id": "e875d7dec6805b8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageColorizer(\n",
      "  (enc1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (enc2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (enc3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (up1): Upsample(scale_factor=2.0, mode='nearest')\n",
      "  (dec1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (up2): Upsample(scale_factor=2.0, mode='nearest')\n",
      "  (dec2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (final): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-26T15:03:10.912633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 8. Training loop mit Loss-Tracking\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for gray, color in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):\n",
    "        gray  = gray.to(device)\n",
    "        color = color.to(device)\n",
    "        # forward\n",
    "        outputs = model(gray)\n",
    "        loss    = criterion(outputs, color)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * gray.size(0)\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    loss_history.append(epoch_loss)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} — Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# 9. Trainingskurve plotten\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, num_epochs+1), loss_history, marker='o')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 10. Ergebnisse anzeigen\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    gray_batch, true_color_batch = next(iter(dataloader))\n",
    "    gray_batch  = gray_batch.to(device)\n",
    "    pred_batch  = model(gray_batch).cpu()\n",
    "\n",
    "n_display = min(5, gray_batch.size(0))\n",
    "fig, axes = plt.subplots(n_display, 3, figsize=(12, 4 * n_display))\n",
    "for i in range(n_display):\n",
    "    axes[i,0].imshow(gray_batch[i].cpu().squeeze(), cmap='gray')\n",
    "    axes[i,0].set_title('Input (Gray)')\n",
    "    axes[i,0].axis('off')\n",
    "\n",
    "    axes[i,1].imshow(pred_batch[i].permute(1,2,0))\n",
    "    axes[i,1].set_title('Predicted')\n",
    "    axes[i,1].axis('off')\n",
    "\n",
    "    axes[i,2].imshow(true_color_batch[i].permute(1,2,0))\n",
    "    axes[i,2].set_title('Ground Truth')\n",
    "    axes[i,2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c5b432d4a8bd4d82",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   2%|▏         | 5/270 [00:05<04:12,  1.05batch/s]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
