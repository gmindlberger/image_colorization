Auto-Colorizer für Landschaftsbilder (von Gabriel²; Mindlberger und Kraljic)

Ein auf Deep Learning basierendes Tool zur automatischen Kolorierung und Restauration von Schwarz-Weiß-Fotos.
Besonders geeignet, um Erinnerungen für ältere Menschen mit kognitiven Einschränkungen (z.B. Demenz) wieder lebendig werden zu lassen.

## Inhaltsverzeichnis
1. Business Understanding
2. Data Understanding
3. Data Preparation
4. Modelling
5. Evaluation
6. Deployment

## Business Understanding:
Zielgruppe: Senior mit eingeschränktem Farb- und Bildverständnis (z.B. Demenz)
Problem: Historische Schwarz-Weiß-Bilder sind schwer erkennbar und verlieren emotionale Wirkung.
Zielgruppe: Historiker zur restauration von Bildern
Problem: Historische Schwarz-Weiß-Bilder könnten ausgebleicht oder schon beschädigt sein (z.B. abblätternder Farbe).
Lösung: Automatische Kolorierung zur Restauration (zur Steigerung der visuellen Klarheit und emotionalen Ansprache).

## Data Understanding
Quelle: Kaggle-Datensatz (User: arnaud58 Name: landscape-pictures)
Dateiformat: JPG
Auflösung: Variierend, Zielskalierung auf max. 180x180 px (Aufgrund der GPU-Ressourcen)
Merkmale: Natürliche Landschaften – Fokus auf Farben, Kontrast
Erste Analysen: siehe data_inspection.ipynb (Dateianzahl, Größenverteilung, etc.)

## Data Preparation
Schritte:
1. Download per kagglehub
2. Dateien einheitlich umbenennen (001.jpg, 002.jpg, …)
3. PyTorch-Dataset ImageColorizerDataset erstellt
4. LAB-Konvertierung: L-Kanal als Input, AB-Kanäle als Ziel; L-Kanal ist der Gray-Scale und AB-Kanäle sind die Farbkanäle
5. Visual-Checks (Shapes & Wertebereiche) und Grid-Preview

## Modelling
Implementierte Architekturen (neuronal_nets):
Klassischer Autoencoder (ImageColorizer, ImageSuperRes, ImageColorizerLab)
Autoencoder mit vortrainierten Gewichten (ColorizeNet)
U-Net (UNet)
U-Net mit ResidualBlock (UNetRes)
Hyperparameter: Bildgröße, Lernrate, Batch-Size, Epochen
Trainierte Modelle wurden jeweils gespeichert. Das beste Modell wurde zusätzlich für 60 Epochen trainiert.
Optimierung: Grid-Search

## Evaluation
Quantitative Metriken: Loss-Functions (Validation und Training)
    weitere Evaluation (evaluation.py): PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index)
    Zusätzlich folgte CIEDE2000, weil PSNR und SSIM für uns nicht Aussagekräftig genug waren.
Qualitative Checks: Manuelle Gegenüberstellung Original vs. Kolorierung

## Deployment:
Git-Hub-Repository für Code und Dokumentation
Zusätzlicher Upload als .zip File auf Moodle

## Technologies Used
- Programming Language: Python
- Frameworks: PyTorch, NumPy, Matplotlib, Pandas, OpenCV, SKImage, tqdm, PIL, Kaggle API

## Project Structure
├── dataloader.py     # Dataset-Klasse (LAB-Konvertierung)
├── evaluation.py     # PSNR, SSIM, CIEDE2000
├── grid_search.py    # Hyperparameter-Search & Visualisierung
├── neural_nets.py    # Modell-Definitionen
├── trainer.py        # Training, Validierung
└── notebooks/
    └── autoencoder.ipynb       # Interaktive Pipeline
    └── data_inspection.ipynb   # Datenüberblick
Additional directorys and files: Gespeichertes Modell, Bewertung der Daten, Graphen der Daten und Beispielbilder